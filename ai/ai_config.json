{
  "version": "1.0.0",
  "description": "AI optimization configuration for CSAL repository - embedding, retrieval, and semantic indexing strategies",
  "last_updated": "2025-11-01",

  "embedding": {
    "default_model": "text-embedding-3-large",
    "models": {
      "text-embedding-3-large": {
        "provider": "openai",
        "dimensions": 3072,
        "max_tokens": 8191,
        "use_case": "High-quality semantic search for documentation",
        "cost_per_1k_tokens": 0.00013
      },
      "text-embedding-3-small": {
        "provider": "openai",
        "dimensions": 1536,
        "max_tokens": 8191,
        "use_case": "Faster, cheaper embeddings for code",
        "cost_per_1k_tokens": 0.00002
      },
      "embed-english-v3.0": {
        "provider": "cohere",
        "dimensions": 1024,
        "max_tokens": 512,
        "use_case": "Alternative embedding model",
        "cost_per_1k_tokens": 0.0001
      }
    },
    "chunking": {
      "strategy": "semantic",
      "methods": {
        "semantic": {
          "description": "Split by semantic boundaries (paragraphs, sections)",
          "max_tokens": 512,
          "overlap_tokens": 50,
          "split_on": ["\\n\\n", "\\n## ", "\\n### "],
          "use_for": ["documentation", "research_papers"]
        },
        "fixed": {
          "description": "Fixed-size chunks with overlap",
          "max_tokens": 400,
          "overlap_tokens": 100,
          "use_for": ["code", "logs"]
        },
        "document": {
          "description": "Embed entire document (for small docs)",
          "max_tokens": 2000,
          "use_for": ["module_specs", "experiment_reports"]
        }
      }
    }
  },

  "vector_store": {
    "recommended_provider": "pinecone",
    "providers": {
      "pinecone": {
        "dimensions": 3072,
        "metric": "cosine",
        "pod_type": "p1.x1",
        "replicas": 1,
        "namespaces": [
          "docs_foundations",
          "docs_research",
          "docs_design",
          "docs_implementation",
          "docs_experiments",
          "docs_reports",
          "docs_program",
          "code_modules",
          "code_agents",
          "memory_episodic",
          "memory_semantic"
        ]
      },
      "qdrant": {
        "dimensions": 3072,
        "metric": "cosine",
        "collections": [
          "csal_documentation",
          "csal_code",
          "csal_memory"
        ]
      }
    }
  },

  "metadata_schema": {
    "required_fields": [
      "document_type",
      "last_update",
      "title"
    ],
    "optional_fields": [
      "cognitive_function",
      "brain_analogue",
      "ai_mapping",
      "module",
      "tags",
      "status",
      "version",
      "author"
    ],
    "field_definitions": {
      "document_type": {
        "type": "string",
        "enum": [
          "foundation",
          "research",
          "design",
          "implementation",
          "experiment",
          "report",
          "program",
          "code",
          "memory"
        ],
        "description": "Category of document"
      },
      "cognitive_function": {
        "type": "string",
        "enum": [
          "executive",
          "memory",
          "attention",
          "perception",
          "learning",
          "creativity",
          "emotion",
          "language",
          "social",
          "metacognition",
          "regulation",
          "meta"
        ],
        "description": "Which cognitive function this relates to"
      },
      "brain_analogue": {
        "type": "string",
        "examples": [
          "hippocampus",
          "prefrontal_cortex",
          "amygdala",
          "default_mode_network",
          "anterior_cingulate_cortex"
        ],
        "description": "Biological brain region or network"
      },
      "ai_mapping": {
        "type": "string",
        "examples": [
          "vector_database",
          "working_memory_cache",
          "attention_mechanism",
          "planning_agent",
          "reinforcement_learning"
        ],
        "description": "Computational/AI equivalent"
      },
      "module": {
        "type": "string",
        "examples": [
          "perception",
          "working_memory",
          "episodic_memory",
          "executive_controller",
          "creativity_engine"
        ],
        "description": "Which cognitive module this implements or documents"
      },
      "tags": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Freeform tags for categorization"
      },
      "last_update": {
        "type": "string",
        "format": "date",
        "description": "Last modified date (YYYY-MM-DD)"
      },
      "status": {
        "type": "string",
        "enum": [
          "draft",
          "active",
          "completed",
          "deprecated"
        ],
        "description": "Document lifecycle status"
      }
    }
  },

  "retrieval_strategies": {
    "hybrid_search": {
      "description": "Combine vector similarity with metadata filtering",
      "steps": [
        "1. Apply metadata filters (e.g., document_type, cognitive_function)",
        "2. Perform vector similarity search on filtered set",
        "3. Rerank results using cross-encoder",
        "4. Return top-k"
      ],
      "parameters": {
        "top_k": 10,
        "rerank_top_k": 5,
        "similarity_threshold": 0.7
      }
    },
    "multi_query": {
      "description": "Generate multiple query variations for robustness",
      "steps": [
        "1. Generate 3-5 query reformulations using LLM",
        "2. Run vector search for each query",
        "3. Merge and deduplicate results",
        "4. Rerank by aggregated scores"
      ]
    },
    "hierarchical_retrieval": {
      "description": "Start broad, then narrow down",
      "steps": [
        "1. Retrieve document summaries/overviews",
        "2. Present to user/LLM",
        "3. Based on selection, retrieve detailed chunks from chosen documents"
      ]
    },
    "contextual_retrieval": {
      "description": "Use conversation context to improve relevance",
      "steps": [
        "1. Combine user query with conversation history",
        "2. Extract key entities and topics",
        "3. Use as metadata filters",
        "4. Perform hybrid search"
      ]
    }
  },

  "prompt_templates": {
    "documentation_query": {
      "template": "Given the CSAL cognitive architecture documentation, answer the following question:\n\nQuestion: {query}\n\nRelevant context:\n{context}\n\nProvide a clear, technical answer with references to specific modules or documents.",
      "variables": ["query", "context"]
    },
    "code_generation": {
      "template": "You are implementing a cognitive module for the CSAL project.\n\nModule: {module_name}\nBrain Analogue: {brain_region}\nFunctional Requirements: {requirements}\n\nRelevant code examples:\n{examples}\n\nGenerate the implementation in Python, following the specification.",
      "variables": ["module_name", "brain_region", "requirements", "examples"]
    },
    "cognitive_analogy": {
      "template": "Based on the CSAL framework, what is the AI/computational equivalent of the following brain function?\n\nBrain Region/Network: {brain_region}\nFunction: {function_description}\n\nRelevant mappings from documentation:\n{context}\n\nProvide the computational analogue and explain the mapping.",
      "variables": ["brain_region", "function_description", "context"]
    },
    "experiment_design": {
      "template": "Design an experiment to validate the following cognitive module:\n\nModule: {module_name}\nHypothesis: {hypothesis}\n\nExisting experiment templates:\n{templates}\n\nProvide a detailed experimental design following the CSAL template.",
      "variables": ["module_name", "hypothesis", "templates"]
    }
  },

  "indexing_priority": {
    "high": [
      "docs/00_Foundations/*",
      "docs/02_Design/*",
      "docs/03_Implementation/*"
    ],
    "medium": [
      "docs/01_Research/*",
      "docs/04_Experiments/*",
      "src/*"
    ],
    "low": [
      "docs/05_Reports/*",
      "docs/06_Program/*"
    ]
  },

  "update_frequency": {
    "real_time": [
      "src/modules/*",
      "src/agents/*"
    ],
    "daily": [
      "docs/02_Design/*",
      "docs/03_Implementation/*"
    ],
    "weekly": [
      "docs/01_Research/*",
      "docs/04_Experiments/*"
    ],
    "monthly": [
      "docs/05_Reports/*",
      "docs/06_Program/*"
    ]
  },

  "integration_examples": {
    "python_embedding": {
      "description": "Example code for embedding documents in Python",
      "code": "from openai import OpenAI\n\nclient = OpenAI()\n\ndef embed_document(text: str, model='text-embedding-3-large'):\n    response = client.embeddings.create(\n        input=text,\n        model=model\n    )\n    return response.data[0].embedding\n\n# Usage\nembedding = embed_document('Example text')"
    },
    "pinecone_upsert": {
      "description": "Example code for upserting to Pinecone",
      "code": "from pinecone import Pinecone\n\npc = Pinecone(api_key='your-api-key')\nindex = pc.Index('csal-docs')\n\nindex.upsert(\n    vectors=[\n        {\n            'id': 'doc-001',\n            'values': embedding,\n            'metadata': {\n                'document_type': 'design',\n                'cognitive_function': 'memory',\n                'title': 'Episodic Memory Spec'\n            }\n        }\n    ],\n    namespace='docs_design'\n)"
    },
    "semantic_search": {
      "description": "Example semantic search query",
      "code": "query_embedding = embed_document('How does working memory work?')\n\nresults = index.query(\n    vector=query_embedding,\n    top_k=10,\n    filter={\n        'cognitive_function': 'memory',\n        'document_type': {'$in': ['design', 'implementation']}\n    },\n    namespace='docs_design',\n    include_metadata=True\n)\n\nfor match in results.matches:\n    print(f\"Score: {match.score}\")\n    print(f\"Title: {match.metadata['title']}\")\n    print(f\"Type: {match.metadata['document_type']}\")"
    }
  },

  "recommended_tools": {
    "embedding_generation": [
      "OpenAI Python SDK",
      "Cohere Python SDK",
      "LangChain (for orchestration)"
    ],
    "vector_databases": [
      "Pinecone (managed, easiest)",
      "Qdrant (open-source, self-hosted)",
      "Weaviate (with built-in ML)"
    ],
    "chunking": [
      "LangChain TextSplitter",
      "tiktoken (token counting)",
      "Custom semantic splitters"
    ],
    "retrieval": [
      "LangChain Retrievers",
      "LlamaIndex",
      "Custom RAG pipelines"
    ]
  },

  "performance_targets": {
    "embedding_latency": "< 200ms per document",
    "search_latency": "< 500ms for top-10 results",
    "indexing_throughput": "> 100 docs/minute",
    "recall_at_10": "> 0.8 (80% of relevant docs in top 10)"
  },

  "monitoring": {
    "metrics_to_track": [
      "embedding_generation_time",
      "search_latency",
      "recall_precision",
      "cache_hit_rate",
      "api_costs",
      "storage_usage"
    ],
    "logging": {
      "log_all_queries": true,
      "log_retrieval_results": true,
      "log_performance_metrics": true
    }
  }
}
